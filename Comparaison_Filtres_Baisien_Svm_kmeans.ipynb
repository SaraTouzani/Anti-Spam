{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import os\n",
    "import codecs\n",
    "import re\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "NEWLINE = '\\n'\n",
    "SKIP_FILES = {'cmds'}\n",
    "\n",
    "#Text Processing\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#Text Processing\n",
    "def preprocess(raw) :\n",
    "    wordlist = word_tokenize(raw)\n",
    "    returnlist = []\n",
    "    for word in wordlist :\n",
    "        if (word not in stopwords.words(\"english\")) :\n",
    "            if (word[0] in (('1','2','3','4','5','6','7','8','9','0','&','(','-','_','ç','é','à',')','=','+','°','~','#'))) :\n",
    "                returnlist.append('#')\n",
    "            else :\n",
    "                returnlist.append(stemmer.stem(word))\n",
    "    return returnlist\n",
    "\n",
    "def read_files(path):\n",
    "    for root, dir_names, file_names in os.walk(path):\n",
    "        for path in dir_names:\n",
    "            read_files(os.path.join(root, path))\n",
    "        for file_name in file_names:\n",
    "            if file_name not in SKIP_FILES:\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    lines = []\n",
    "                    f = open(file_path, encoding=\"latin-1\")\n",
    "                    for line in f:\n",
    "                        lines.append(line)\n",
    "\n",
    "                    f.close()\n",
    "                    content = NEWLINE.join(lines)\n",
    "                    yield file_path, content\n",
    "\n",
    "def build_data_frame(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for file_name, text in read_files(path):\n",
    "        rows.append({'text': text, 'class': classification})\n",
    "        index.append(file_name)\n",
    "\n",
    "    data_frame = DataFrame(rows, index=index)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing de Données"
   ]
  },
  
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0638.2000-03-20.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: @ ect . enron . com email notificatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/2506.2000-10-10.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: union carbide - seadrift\\n\\ndaren\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0479.2000-02-24.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: midcon invoices\\n\\nkellie -\\n\\ni rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/2285.2004-09-26.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: fw : hungry 30 to 40 girls wants to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/5063.2001-11-12.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: pipelines that still have dial in acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/2925.2000-11-22.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : cornhusker\\n\\nthanks for the inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0907.2000-04-11.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : fyi - wellhead portfolio\\n\\nwho ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4922.2005-07-25.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: u . s . robotics - analogue / wired c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4478.2005-05-12.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: fda approved\\n\\nwe are one of the top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0188.2000-01-12.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : hl &amp; p for 12 / 99\\n\\nit is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4463.2005-05-08.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: highest gains without guesswork\\n\\nwy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/2584.2000-10-18.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: tenaska iv gas management agreement (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/3984.2001-03-23.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: phillips - 4 / 01\\n\\ncarlos ,\\n\\ni cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0783.2000-03-29.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : resume attached\\n\\nliz is an mit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/2501.2000-10-10.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: rate for tenaska deal\\n\\ndaren ,\\n\\nw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0527.2000-03-01.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: organizational announcement\\n\\nplease...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4665.2005-06-09.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: a more radiant you\\n\\nact now . get y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4486.2005-05-15.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: all mens need this 5 j\\n\\nci - ialis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/2317.2000-09-22.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: revised : eastrans nomination change ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/0779.2004-04-05.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: cheap v . iagra , phentermine , xa . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/1776.2000-07-27.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron / hpl actuals for july 26 , 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/4436.2001-04-30.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: conoco , inc . katy tailgate contract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/3413.2001-01-24.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: eastrans nomination effective 1 / 25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4320.2005-04-20.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: give a man a fish and he will eat for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/2357.2000-09-27.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: accum .\\n\\n- - - - - - - - - - - - - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/0686.2004-03-20.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: fwd : real buy v / a / lium ) xan @ x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4377.2005-04-25.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: stock market standouts\\n\\ninfotex hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/0289.2004-01-23.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: paliourg get the doctors time 4 freee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/4263.2001-04-10.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : noms / actual flow for 4 / 09 / ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0196.2000-01-13.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: entex estimates for 12 / 99\\n\\nattach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0570.2000-03-07.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: eops salary survey questionnaire\\n\\np...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/5020.2005-08-16.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: funny\\n\\nmay aplomb be angola may pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/1153.2000-05-26.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: nomination 6 / 1 / 2000 - eastrans\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/2246.2000-09-15.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: the enrononline games\\n\\n- - - - - - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/3595.2001-02-16.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : first delivery - helmerich &amp; pay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/3135.2000-12-19.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: tenaska iv pricing\\n\\ni think we need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4615.2005-06-02.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: re : keeping it like a rock\\n\\nhello ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/2977.2000-11-30.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: sitara / cpr availability\\n\\nto all s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0275.2000-01-28.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: follow - up\\n\\njust following up to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4862.2005-07-11.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: check the superb specials on top - se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/3758.2001-03-12.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: registration welcome email\\n\\nthank y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4720.2005-06-16.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: want something extra in bed ?\\n\\nhi t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/5102.2001-12-08.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\n\\nho ho ho , we ' re ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/3319.2004-12-27.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: over 160 fda approved meds\\n\\n% rnd _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/3009.2004-12-01.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: have the ability to attract members o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/4903.2001-09-14.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: fw : black marlin\\n\\nhave you had a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/3963.2005-03-03.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: you need this abazis\\n\\nlook at this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/1977.2000-08-18.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: unify passwords will be reset under s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/3789.2005-02-10.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: looking for a new date\\n\\nfind a new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/4614.2001-05-24.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: eastrans nomination for 6 / 01 / 01\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/1144.2000-05-25.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: june 2000 co - owners volumes\\n\\n- - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/2829.2004-11-16.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: approval # 5146\\n\\nhello ,\\n\\nwe sent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0384.2000-02-09.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: pathing procedures for buybacks\\n\\nto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/4647.2005-06-05.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: copy from cassette tape to mp 3 and v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/3845.2005-02-15.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: 108 mbps wireless firewall 4 - port r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/spam/2526.2004-10-17.GP.spam.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: your contact info\\n\\n? \" ? ? ?  ?  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/0624.2000-03-19.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: team room\\n\\n- - - - - - - - - - - - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/3524.2001-02-05.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: eastrans nominations change effective...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/3832.2001-03-16.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : noms / actual flow for 03 / 15\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/toutou/Téléchargements/data/enron1/ham/4800.2001-08-09.farmer.ham.txt</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: fw : executed agency - ena and tenask...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   class  \\\n",
       "/home/toutou/Téléchargements/data/enron1/ham/06...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/25...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/04...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/2...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/50...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/29...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/09...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/01...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/25...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/39...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/07...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/25...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/05...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/23...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/0...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/17...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/44...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/34...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/23...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/0...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/0...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/42...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/01...   ham   \n",
       "...                                                  ...   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/05...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/5...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/11...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/22...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/35...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/31...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/29...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/02...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/37...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/51...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/3...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/3...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/49...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/3...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/19...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/3...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/46...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/11...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/2...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/03...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/3...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/spam/2...  spam   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/06...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/35...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/38...   ham   \n",
       "/home/toutou/Téléchargements/data/enron1/ham/48...   ham   \n",
       "\n",
       "                                                                                                 text  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/06...  Subject: @ ect . enron . com email notificatio...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/25...  Subject: union carbide - seadrift\\n\\ndaren\\n\\n...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/04...  Subject: midcon invoices\\n\\nkellie -\\n\\ni rese...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/2...  Subject: fw : hungry 30 to 40 girls wants to d...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/50...  Subject: pipelines that still have dial in acc...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/29...  Subject: re : cornhusker\\n\\nthanks for the inf...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/09...  Subject: re : fyi - wellhead portfolio\\n\\nwho ...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: u . s . robotics - analogue / wired c...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: fda approved\\n\\nwe are one of the top...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/01...  Subject: re : hl & p for 12 / 99\\n\\nit is the ...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: highest gains without guesswork\\n\\nwy...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/25...  Subject: tenaska iv gas management agreement (...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/39...  Subject: phillips - 4 / 01\\n\\ncarlos ,\\n\\ni cr...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/07...  Subject: re : resume attached\\n\\nliz is an mit...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/25...  Subject: rate for tenaska deal\\n\\ndaren ,\\n\\nw...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/05...  Subject: organizational announcement\\n\\nplease...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: a more radiant you\\n\\nact now . get y...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: all mens need this 5 j\\n\\nci - ialis ...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/23...  Subject: revised : eastrans nomination change ...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/0...  Subject: cheap v . iagra , phentermine , xa . ...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/17...  Subject: enron / hpl actuals for july 26 , 200...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/44...  Subject: conoco , inc . katy tailgate contract...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/34...  Subject: eastrans nomination effective 1 / 25 ...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: give a man a fish and he will eat for...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/23...  Subject: accum .\\n\\n- - - - - - - - - - - - - ...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/0...  Subject: fwd : real buy v / a / lium ) xan @ x...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: stock market standouts\\n\\ninfotex hol...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/0...  Subject: paliourg get the doctors time 4 freee...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/42...  Subject: re : noms / actual flow for 4 / 09 / ...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/01...  Subject: entex estimates for 12 / 99\\n\\nattach...  \n",
       "...                                                                                               ...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/05...  Subject: eops salary survey questionnaire\\n\\np...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/5...  Subject: funny\\n\\nmay aplomb be angola may pri...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/11...  Subject: nomination 6 / 1 / 2000 - eastrans\\n\\...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/22...  Subject: the enrononline games\\n\\n- - - - - - ...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/35...  Subject: re : first delivery - helmerich & pay...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/31...  Subject: tenaska iv pricing\\n\\ni think we need...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: re : keeping it like a rock\\n\\nhello ...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/29...  Subject: sitara / cpr availability\\n\\nto all s...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/02...  Subject: follow - up\\n\\njust following up to m...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: check the superb specials on top - se...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/37...  Subject: registration welcome email\\n\\nthank y...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: want something extra in bed ?\\n\\nhi t...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/51...  Subject: neon retreat\\n\\nho ho ho , we ' re ar...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/3...  Subject: over 160 fda approved meds\\n\\n% rnd _...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/3...  Subject: have the ability to attract members o...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/49...  Subject: fw : black marlin\\n\\nhave you had a c...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/3...  Subject: you need this abazis\\n\\nlook at this ...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/19...  Subject: unify passwords will be reset under s...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/3...  Subject: looking for a new date\\n\\nfind a new ...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/46...  Subject: eastrans nomination for 6 / 01 / 01\\n...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/11...  Subject: june 2000 co - owners volumes\\n\\n- - ...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/2...  Subject: approval # 5146\\n\\nhello ,\\n\\nwe sent...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/03...  Subject: pathing procedures for buybacks\\n\\nto...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/4...  Subject: copy from cassette tape to mp 3 and v...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/3...  Subject: 108 mbps wireless firewall 4 - port r...  \n",
       "/home/toutou/Téléchargements/data/enron1/spam/2...  Subject: your contact info\\n\\n? \" ? ? ?  ?  ...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/06...  Subject: team room\\n\\n- - - - - - - - - - - - ...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/35...  Subject: eastrans nominations change effective...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/38...  Subject: re : noms / actual flow for 03 / 15\\n...  \n",
       "/home/toutou/Téléchargements/data/enron1/ham/48...  Subject: fw : executed agency - ena and tenask...  \n",
       "\n",
       "[5172 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAM = 'ham'\n",
    "SPAM = 'spam'\n",
    "\"\"\",\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron2/spam',    SPAM),\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron3/spam',    SPAM),\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron4/spam',      SPAM),\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron5/spam',    SPAM),\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron6/spam',  SPAM),\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron1/ham',        HAM),\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron2/ham',    HAM),\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron3/ham',    HAM),\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron4/ham',      HAM),\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron5/ham',    HAM),\n",
    "    ('/home/techmen/Desktop/IA/dataset/enron6/ham',  HAM),\"\"\"\n",
    "SOURCES = [\n",
    "    ('/home/toutou/Téléchargements/data/enron1/spam',        SPAM),\n",
    "    ('/home/toutou/Téléchargements/data/enron1/ham',        HAM)\n",
    "]\n",
    "\n",
    "data = DataFrame({'text': [], 'class': []})\n",
    "for path, classification in SOURCES:\n",
    "    data = data.append(build_data_frame(path, classification))\n",
    "\n",
    "data = data.reindex(numpy.random.permutation(data.index))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp=[]\n",
    "hm=[]\n",
    "liste=[]\n",
    "for i in range(len(data['class'])):\n",
    "    if data['class'][i]=='spam':\n",
    "        liste=preprocess(data['text'][i])\n",
    "        sp.extend(liste)\n",
    "    else:\n",
    "        liste=preprocess(data['text'][i])\n",
    "        hm.extend(liste)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: @ ect . enron . com email notification !\\n\\nwe are one @ enron . com !\\n\\nplease be aware of the following senders were automatically notified to ( a ) .\\n\\nstop sending internet mail to your @ ect . enron . com address and to ( b ) . send\\n\\nfuture internet communications to daren . j . farmer @ enron . com :\\n\\nfpam _ @ hotmail . com , mjones 7 @ txu . com\\n\\nreminder :\\n\\nyour @ ect . enron . com address should not be used any longer and will be\\n\\ndeactivated soon . so please make sure these contacts switch to your new\\n\\n@ enron . com address . if you have subscribed to mailing lists , please make\\n\\nsure to update your addresses there as well .\\n\\nand\\n\\nyour shortname @ enron . com address ( i . e . jsmith @ enron . com ) will continue to\\n\\nwork , even though your formal address is longname @ enron . com ( i . e .\\n\\njohn . smith @ enron . com )\\n\\nplease do not reply to this message as it was automatically generated .'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3672\n",
       "spam    1500\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].values\n",
    "worddata =[word_tokenize(c) for c in data['text'].values ]\n",
    "data['class'].value_counts()\n",
    "#data['text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['step', 291],\n",
       " ['prepar', 115],\n",
       " ['kettler', 1],\n",
       " ['tri', 851],\n",
       " ['kaufman', 3],\n",
       " ['rglover', 2],\n",
       " ['?', 2774],\n",
       " ['assur', 14],\n",
       " ['pasadena', 10],\n",
       " ['buyer', 55],\n",
       " ['gg', 349],\n",
       " ['marriag', 2],\n",
       " ['manual', 41],\n",
       " ['glenda', 2],\n",
       " ['child', 51],\n",
       " ['loraleigh', 1],\n",
       " ['backgound', 1],\n",
       " ['sql', 4],\n",
       " ['kleberg', 14],\n",
       " ['greed', 49],\n",
       " ['solver', 1],\n",
       " ['layni', 4],\n",
       " ['carrington', 4],\n",
       " ['idaho', 1],\n",
       " ['exact', 29],\n",
       " ['dbaumba', 2],\n",
       " ['ne', 14361],\n",
       " ['domino', 2],\n",
       " ['circumst', 7],\n",
       " ['revoir', 1],\n",
       " ['citywid', 1],\n",
       " ['upto', 1],\n",
       " ['tino', 2],\n",
       " ['cat', 1603],\n",
       " ['fitzgerald', 3],\n",
       " ['aspx', 1],\n",
       " ['benoitjasonp', 1],\n",
       " ['egarden', 1],\n",
       " ['persist', 5],\n",
       " ['larger', 15],\n",
       " ['stuck', 2],\n",
       " ['salt', 8],\n",
       " ['evp', 1],\n",
       " ['clarifi', 27],\n",
       " ['hbd', 3],\n",
       " ['amerac', 1],\n",
       " ['old', 467],\n",
       " ['kleb', 16],\n",
       " ['bonsai', 1],\n",
       " ['baughman', 4],\n",
       " ['gasolin', 4],\n",
       " ['similarli', 0],\n",
       " ['ind', 1221],\n",
       " ['whitton', 1],\n",
       " ['crcandmac', 1],\n",
       " ['spectrum', 3],\n",
       " ['swxl', 2],\n",
       " ['prod', 1214],\n",
       " ['wu', 10],\n",
       " ['stenophon', 1],\n",
       " ['ident', 231],\n",
       " ['conflict', 12],\n",
       " ['dkessler', 1],\n",
       " ['caribbean', 3],\n",
       " ['mansfield', 1],\n",
       " ['gpg', 87],\n",
       " ['truong', 14],\n",
       " ['na', 7897],\n",
       " ['stroll', 2],\n",
       " ['irvin', 7],\n",
       " ['stefaniedavi', 1],\n",
       " ['womb', 1],\n",
       " ['human', 17],\n",
       " ['inappropri', 2],\n",
       " ['approx', 133],\n",
       " ['gentlemen', 7],\n",
       " ['ringhoff', 1],\n",
       " ['gina', 622],\n",
       " ['degre', 15],\n",
       " ['telephoni', 0],\n",
       " ['alik', 4],\n",
       " ['provis', 35],\n",
       " ['fraction', 3],\n",
       " ['worth', 68],\n",
       " ['lavonn', 1],\n",
       " ['anxious', 4],\n",
       " ['distort', 1],\n",
       " ['unexcit', 1],\n",
       " ['lamar', 1],\n",
       " ['she', 1108],\n",
       " ['keithbird', 1],\n",
       " ['hirko', 3],\n",
       " ['angri', 0],\n",
       " ['dh', 39],\n",
       " ['goodby', 3],\n",
       " ['ess', 3349],\n",
       " ['drew', 21],\n",
       " ['majorrwitz', 2],\n",
       " ['decentr', 1],\n",
       " ['estesfinanci', 1],\n",
       " ['pocket', 3],\n",
       " ['contract', 1145],\n",
       " ['ljm', 3],\n",
       " ['poverti', 1],\n",
       " ['petual', 1],\n",
       " ['everett', 1],\n",
       " ['asia', 7],\n",
       " ['darl', 1],\n",
       " ['vallejo', 1],\n",
       " ['zhou', 2],\n",
       " ['enrich', 2],\n",
       " ['jholstea', 1],\n",
       " ['prebid', 4],\n",
       " ['ol', 6409],\n",
       " ['dew', 59],\n",
       " ['spring', 85],\n",
       " ['kelli', 9],\n",
       " ['riversid', 15],\n",
       " ['brain', 6],\n",
       " ['scale', 9],\n",
       " ['syzdek', 4],\n",
       " ['zgoner', 1],\n",
       " ['auburn', 7],\n",
       " ['gpk', 1],\n",
       " ['simpli', 7],\n",
       " ['eolbridg', 1],\n",
       " ['action', 321],\n",
       " ['basic', 15],\n",
       " ['imai', 3],\n",
       " ['toronto', 4],\n",
       " ['soooooooooooooo', 1],\n",
       " ['lannou', 225],\n",
       " ['reavi', 1],\n",
       " ['gig', 5],\n",
       " ['sky', 32],\n",
       " ['unix', 4],\n",
       " ['obscur', 1],\n",
       " ['peg', 36],\n",
       " ['lonestarsteel', 3],\n",
       " ['million', 48],\n",
       " ['valet', 2],\n",
       " ['modul', 3],\n",
       " ['adventur', 3],\n",
       " ['warmong', 1],\n",
       " ['jenn', 130],\n",
       " ['ec', 28139],\n",
       " ['julissa', 2],\n",
       " ['deco', 12],\n",
       " ['mitchem', 1],\n",
       " ['sutton', 22],\n",
       " ['brad', 51],\n",
       " ['coad', 3],\n",
       " ['significantli', 0],\n",
       " ['repsons', 1],\n",
       " ['billion', 16],\n",
       " ['ccernosek', 2],\n",
       " ['committ', 111],\n",
       " ['paig', 5],\n",
       " ['hol', 474],\n",
       " ['unopen', 2],\n",
       " ['can', 1830],\n",
       " ['hav', 3365],\n",
       " ['karl', 9],\n",
       " ['piplin', 2],\n",
       " ['hr', 1162],\n",
       " ['bryce', 47],\n",
       " ['organ', 158],\n",
       " ['victoria', 41],\n",
       " ['throughput', 1],\n",
       " ['riviera', 1],\n",
       " ['cajun', 1],\n",
       " ['keller', 2],\n",
       " ['offens', 2],\n",
       " ['krista', 1],\n",
       " ['jpg', 19],\n",
       " ['dbb', 1],\n",
       " ['copeland', 1],\n",
       " ['terre', 1],\n",
       " ['yore', 7],\n",
       " ['aggreg', 7],\n",
       " ['brassfield', 1],\n",
       " ['bharathi', 1],\n",
       " ['everywher', 2],\n",
       " ['smtpsvc', 1],\n",
       " ['inferior', 1],\n",
       " ['gardner', 6],\n",
       " ['gp', 179],\n",
       " ['atokarz', 1],\n",
       " ['puckett', 2],\n",
       " ['cwolf', 1],\n",
       " ['yet', 117],\n",
       " ['brandon', 8],\n",
       " ['generalist', 4],\n",
       " ['squeemish', 1],\n",
       " ['pearland', 1],\n",
       " ['roo', 134],\n",
       " ['groff', 1],\n",
       " ['virtual', 5],\n",
       " ['cigna', 1],\n",
       " ['ladi', 10],\n",
       " ['fricken', 2],\n",
       " ['cquerol', 1],\n",
       " ['importantli', 0],\n",
       " ['abeckley', 1],\n",
       " ['synhrgi', 0],\n",
       " ['color', 24],\n",
       " ['vale', 157],\n",
       " ['republican', 2],\n",
       " ['lile', 2],\n",
       " ['midpoint', 13],\n",
       " ['bias', 2],\n",
       " ['rbl', 2],\n",
       " ['marcello', 3],\n",
       " ['txt', 1],\n",
       " ['chrissi', 0],\n",
       " ['resorc', 2],\n",
       " ['frmli', 0],\n",
       " ['aladdin', 1],\n",
       " ['chryal', 1],\n",
       " ['mcmichael', 6],\n",
       " ['dabay', 1],\n",
       " ['prelminari', 0],\n",
       " ['``', 0],\n",
       " ['personel', 1],\n",
       " ['insight', 10],\n",
       " ['greenwich', 2],\n",
       " ['pure', 21],\n",
       " ['adamsck', 1],\n",
       " ['sike', 2],\n",
       " ['kleptomania', 1],\n",
       " ['relationship', 21],\n",
       " ['marino', 1],\n",
       " ['formerli', 0],\n",
       " ['known', 15],\n",
       " ['goldston', 3],\n",
       " ['case', 113],\n",
       " ['ultim', 8],\n",
       " ['unbundl', 2],\n",
       " ['wgr', 5],\n",
       " ['delieveri', 0],\n",
       " ['schockl', 2],\n",
       " ['krisaggi', 1],\n",
       " ['exhibit', 25],\n",
       " ['bori', 3],\n",
       " ['nightli', 1],\n",
       " ['firstam', 1],\n",
       " ['johan', 1],\n",
       " ['fernley', 2],\n",
       " ['mage', 95],\n",
       " ['designpath', 1],\n",
       " ['wherebi', 0],\n",
       " ['espllp', 4],\n",
       " ['dewvil', 3],\n",
       " ['theori', 0],\n",
       " ['profit', 27],\n",
       " ['tueday', 1],\n",
       " ['mcauliff', 6],\n",
       " ['pstewart', 1],\n",
       " ['beverli', 0],\n",
       " ['keyshutdown', 1],\n",
       " ['machleit', 10],\n",
       " ['columbia', 27],\n",
       " ['rohan', 1],\n",
       " ['retroact', 16],\n",
       " ['tsb', 8],\n",
       " ['sudden', 1],\n",
       " ['catalina', 1],\n",
       " ['vu', 12],\n",
       " ['inconveni', 9],\n",
       " ['steveharrod', 1],\n",
       " ['mischaracter', 2],\n",
       " ['kofax', 1],\n",
       " ['nielsen', 1],\n",
       " ['wacog', 7],\n",
       " ['jaca', 1],\n",
       " ['fluor', 1],\n",
       " ['discuss', 260],\n",
       " ['teresagil', 1],\n",
       " ['retro', 21],\n",
       " ['twelch', 1],\n",
       " ['lavorato', 10],\n",
       " ['veselack', 1],\n",
       " ['ramirez', 2],\n",
       " ['corpaor', 1],\n",
       " ['abc', 8],\n",
       " ['al', 18322],\n",
       " ['heineman', 1],\n",
       " ['pearson', 2],\n",
       " ['transtion', 2],\n",
       " ['ihrig', 1],\n",
       " ['surpris', 7],\n",
       " ['mkessner', 1],\n",
       " ['presum', 7],\n",
       " ['bacchu', 1],\n",
       " ['peek', 4],\n",
       " ['bateman', 1],\n",
       " ['kforonlin', 1],\n",
       " ['focus', 55],\n",
       " ['koerselman', 4],\n",
       " ['regardless', 18],\n",
       " ['subsidiari', 3],\n",
       " ['scribner', 17],\n",
       " ['haggerti', 0],\n",
       " ['henrietta', 1],\n",
       " ['gim', 1],\n",
       " ['cstonel', 1],\n",
       " ['advisor', 19],\n",
       " ['janin', 2],\n",
       " ['everyth', 65],\n",
       " ['diversif', 4],\n",
       " ['wilmar', 2],\n",
       " ['biblic', 1],\n",
       " ['higgin', 6],\n",
       " ['airam', 3],\n",
       " ['tammypon', 1],\n",
       " ['greet', 6],\n",
       " ['commonpoint', 1],\n",
       " ['ermi', 277],\n",
       " ['invit', 47],\n",
       " ['icon', 13],\n",
       " ['sword', 105],\n",
       " ['agreement', 402],\n",
       " ['labor', 12],\n",
       " ['olymp', 4],\n",
       " ['dtddtd', 1],\n",
       " ['tgp', 12],\n",
       " ['ridicul', 2],\n",
       " ['approxim', 97],\n",
       " ['hamlin', 1],\n",
       " ['offsystem', 21],\n",
       " ['appris', 8],\n",
       " ['kratzer', 2],\n",
       " ['servlet', 1],\n",
       " ['courtney', 4],\n",
       " ['cheesesteak', 1],\n",
       " ['threat', 3],\n",
       " ['depict', 2],\n",
       " ['dietrich', 7],\n",
       " ['follow', 858],\n",
       " ['parrot', 21],\n",
       " ['ctom', 2],\n",
       " ['srr', 2],\n",
       " ['bog', 4],\n",
       " ['borrow', 2],\n",
       " ['reaction', 4],\n",
       " ['presenc', 5],\n",
       " ['babi', 1],\n",
       " ['resolut', 31],\n",
       " ['ragsdal', 1],\n",
       " ['ahernand', 1],\n",
       " ['bradyrobert', 1],\n",
       " ['kathol', 1],\n",
       " ['currect', 1],\n",
       " ['peebl', 4],\n",
       " ['arco', 38],\n",
       " ['whatev', 25],\n",
       " ['bear', 23],\n",
       " ['us', 6276],\n",
       " ['deuteronomi', 0],\n",
       " ['mcdonald', 4],\n",
       " ['lelyveld', 1],\n",
       " ['printer', 5],\n",
       " ['tcastellano', 1],\n",
       " ['talber', 5],\n",
       " ['predict', 5],\n",
       " ['apwo', 1],\n",
       " ['joann', 52],\n",
       " ['brogdin', 1],\n",
       " ['see', 1187],\n",
       " ['atheist', 1],\n",
       " ['tomorrow', 149],\n",
       " ['cporter', 1],\n",
       " ['buerkl', 1],\n",
       " ['hrweb', 5],\n",
       " ['mkwall', 1],\n",
       " ['coupl', 71],\n",
       " ['vaild', 1],\n",
       " ['craft', 4],\n",
       " ['braband', 48],\n",
       " ['abramo', 1],\n",
       " ['dale', 120],\n",
       " ['alsik', 1],\n",
       " ['ewheal', 1],\n",
       " ['cream', 5],\n",
       " ['rfeldman', 1],\n",
       " ['ea', 13531],\n",
       " ['edu', 851],\n",
       " ['unabl', 44],\n",
       " ['croucher', 2],\n",
       " ['tidbit', 1],\n",
       " ['scherlyn', 1],\n",
       " ['cool', 16],\n",
       " ['mhmr', 1],\n",
       " ['alxwilliam', 1],\n",
       " ['cousino', 31],\n",
       " ['solut', 87],\n",
       " ['amt', 6],\n",
       " ['discusss', 1],\n",
       " ['dori', 1],\n",
       " ['career', 9],\n",
       " ['tonya', 16],\n",
       " ['gentri', 0],\n",
       " ['david', 338],\n",
       " ['entranc', 6],\n",
       " ['achiev', 16],\n",
       " ['articl', 5],\n",
       " ['shepperd', 6],\n",
       " ['bland', 2],\n",
       " ['suppos', 30],\n",
       " ['suggest', 102],\n",
       " ['iwl', 1],\n",
       " ['babcock', 1],\n",
       " ['priddi', 0],\n",
       " ['cerrito', 1],\n",
       " ['baweja', 1],\n",
       " ['lund', 4],\n",
       " ['vidal', 1],\n",
       " ['crma', 1],\n",
       " ['snugli', 0],\n",
       " ['janicen', 1],\n",
       " ['drjc', 1],\n",
       " ['sdsnom', 32],\n",
       " ['niedenfuehr', 1],\n",
       " ['escap', 1],\n",
       " ['fw', 460],\n",
       " ['handpick', 2],\n",
       " ['avg', 13],\n",
       " ['aim', 436],\n",
       " ['drag', 9],\n",
       " ['foon', 1],\n",
       " ['happen', 81],\n",
       " ['consum', 36],\n",
       " ['immun', 1],\n",
       " ['larri', 7],\n",
       " ['hey', 879],\n",
       " ['scotland', 1],\n",
       " ['ckoehn', 1],\n",
       " ['adiit', 1],\n",
       " ['emerg', 14],\n",
       " ['businessobject', 1],\n",
       " ['glass', 5],\n",
       " ['fell', 13],\n",
       " ['document', 126],\n",
       " ['tiner', 10],\n",
       " ['tripl', 8],\n",
       " ['equestlnm', 1],\n",
       " ['wc', 54],\n",
       " ['submitt', 50],\n",
       " ['cecilia', 6],\n",
       " ['corina', 1],\n",
       " ['gasdaili', 0],\n",
       " ['mask', 2],\n",
       " ['camlem', 8],\n",
       " ['discrep', 53],\n",
       " ['claus', 1],\n",
       " ['boal', 3],\n",
       " ['balfour', 16],\n",
       " ['dclark', 1],\n",
       " ['decreas', 41],\n",
       " ['shammara', 1],\n",
       " ['workord', 7],\n",
       " ['cincinnati', 2],\n",
       " ['password', 103],\n",
       " ['paycheck', 13],\n",
       " ['smchamp', 1],\n",
       " ['repli', 5],\n",
       " ['personnel', 35],\n",
       " ['accross', 2],\n",
       " ['fischer', 2],\n",
       " ['account', 413],\n",
       " ['coconut', 12],\n",
       " ['jessica', 4],\n",
       " ['edg', 77],\n",
       " ['descript', 40],\n",
       " ['herringangu', 1],\n",
       " ['thumb', 5],\n",
       " ['odessa', 19],\n",
       " ['waldhaus', 1],\n",
       " ['idx', 2],\n",
       " ['exacerb', 1],\n",
       " ['maughmen', 1],\n",
       " ['cdnow', 87],\n",
       " ['redeliv', 185],\n",
       " ['thoroughli', 0],\n",
       " ['lkerr', 1],\n",
       " ['ashley', 5],\n",
       " ['lahost', 3],\n",
       " ['adrial', 3],\n",
       " ['avila', 91],\n",
       " ['donnel', 1],\n",
       " ['finish', 32],\n",
       " ['lauderdal', 1],\n",
       " ['hype', 4],\n",
       " ['wiesepap', 7],\n",
       " ['josef', 1],\n",
       " ['kristi', 28],\n",
       " ['tequila', 2],\n",
       " ['cole', 30],\n",
       " ['rlitvik', 1],\n",
       " ['pleasant', 3],\n",
       " ['beliz', 1],\n",
       " ['fslto', 2],\n",
       " ['planet', 1],\n",
       " ['mccurdi', 0],\n",
       " ['unavoid', 2],\n",
       " ['itg', 16],\n",
       " ['stakehold', 1],\n",
       " ['hymel', 1],\n",
       " ['berri', 0],\n",
       " ['forth', 14],\n",
       " ['pa', 5746],\n",
       " ['ratemak', 2],\n",
       " ['episod', 3],\n",
       " ['maffia', 1],\n",
       " ['actual', 651],\n",
       " ['friendli', 0],\n",
       " ['boot', 14],\n",
       " ['hypothermia', 1],\n",
       " ['ms', 1284],\n",
       " ['hplr', 44],\n",
       " ['calcul', 38],\n",
       " ['dan', 255],\n",
       " ['overdyk', 2],\n",
       " ['commonwealth', 9],\n",
       " ['hppclaw', 1],\n",
       " ['paradi', 5],\n",
       " ['petri', 1],\n",
       " ['spoed', 1],\n",
       " ['trefz', 3],\n",
       " ['dealmak', 6],\n",
       " ['deaton', 11],\n",
       " ['remind', 48],\n",
       " ['blakef', 1],\n",
       " ['fannett', 1],\n",
       " ['program', 115],\n",
       " ['garrettz', 1],\n",
       " ['interrupt', 23],\n",
       " ['teakerl', 4],\n",
       " ['smile', 3],\n",
       " ['frusco', 1],\n",
       " ['deposit', 4],\n",
       " ['involuntari', 0],\n",
       " ['susanwemp', 1],\n",
       " ['quenet', 1],\n",
       " ['unaccount', 63],\n",
       " ['jdf', 5],\n",
       " ['goemsi', 3],\n",
       " ['expert', 9],\n",
       " ['overwhelm', 3],\n",
       " ['gullibl', 0],\n",
       " ['sweeni', 0],\n",
       " ['blanchard', 12],\n",
       " ['dorothi', 0],\n",
       " ['workday', 5],\n",
       " ['senora', 1],\n",
       " ['unsur', 3],\n",
       " ['butt', 53],\n",
       " ['meyer', 234],\n",
       " ['cwc', 1],\n",
       " ['analys', 136],\n",
       " ['wake', 2],\n",
       " ['zipper', 5],\n",
       " ['calphalon', 1],\n",
       " ['buechel', 1],\n",
       " ['downtim', 9],\n",
       " ['darryl', 3],\n",
       " ['faq', 6],\n",
       " ['method', 20],\n",
       " ['bou', 622],\n",
       " ['constant', 4],\n",
       " ['rede', 206],\n",
       " ['novo', 1],\n",
       " ['tanner', 2],\n",
       " ['wagso', 1],\n",
       " ['encrypt', 1],\n",
       " ['matagorda', 9],\n",
       " ['honeymoon', 1],\n",
       " ['ensur', 83],\n",
       " ['bl', 2045],\n",
       " ['lesly', 1],\n",
       " ['attrit', 1],\n",
       " ['custodi', 0],\n",
       " ['especi', 14],\n",
       " ['flame', 1],\n",
       " ['per', 2197],\n",
       " ['weaken', 1],\n",
       " ['darin', 2],\n",
       " ['noncrit', 1],\n",
       " ['transmit', 14],\n",
       " ['denot', 6],\n",
       " ['francisco', 6],\n",
       " ['bush', 18],\n",
       " ['marsden', 1],\n",
       " ['steven', 41],\n",
       " ['trade', 280],\n",
       " ['camoil', 1],\n",
       " ['fairchildpub', 1],\n",
       " ['ame', 1559],\n",
       " ['acosta', 1],\n",
       " ['data', 262],\n",
       " ['girl', 15],\n",
       " ['brokenheart', 1],\n",
       " ['tholen', 1],\n",
       " ['add', 913],\n",
       " ['graci', 5],\n",
       " ['pge', 75],\n",
       " ['oakhil', 1],\n",
       " ['wyndham', 9],\n",
       " ['elliott', 11],\n",
       " ['wipe', 2],\n",
       " ['edm', 93],\n",
       " ['llc', 48],\n",
       " ['consemiu', 40],\n",
       " ['pearc', 4],\n",
       " ['dimichel', 1],\n",
       " ['workpiec', 1],\n",
       " ['tao', 2],\n",
       " ['herebi', 0],\n",
       " ['simul', 5],\n",
       " ['nomlog', 7],\n",
       " ['shape', 4],\n",
       " ['savor', 2],\n",
       " ['brag', 4],\n",
       " ['citizen', 1],\n",
       " ['footwork', 2],\n",
       " ['spray', 1],\n",
       " ['griffin', 39],\n",
       " ['galard', 1],\n",
       " ['martha', 12],\n",
       " ['lza', 4],\n",
       " ['workov', 2],\n",
       " ['van', 634],\n",
       " ['tube', 1],\n",
       " ['thei', 522],\n",
       " ['casella', 2],\n",
       " ['mcadam', 1],\n",
       " ['marykpowl', 1],\n",
       " ['peoplesoft', 1],\n",
       " ['bidweek', 11],\n",
       " ['dot', 6],\n",
       " ['cleer', 1],\n",
       " ['port', 1687],\n",
       " ['kristian', 1],\n",
       " ['intercompani', 0],\n",
       " ['particip', 71],\n",
       " ['cliff', 15],\n",
       " ['volp', 5],\n",
       " ['gautam', 1],\n",
       " ['redir', 20],\n",
       " ['negoti', 50],\n",
       " ['environmentalist', 1],\n",
       " ['vanderbilt', 1],\n",
       " ['rochel', 1],\n",
       " ['middleiniti', 1],\n",
       " ['eas', 4005],\n",
       " ['umbow', 1],\n",
       " ['tatton', 1],\n",
       " ['rhaaia', 1],\n",
       " ['shackley', 1],\n",
       " ['remeb', 1],\n",
       " ['kinneman', 1],\n",
       " ['homesbybetti', 0],\n",
       " ['lifestrategi', 0],\n",
       " ['shepherd', 6],\n",
       " ['tspo', 1],\n",
       " ['unsubscrib', 70],\n",
       " ['peripher', 1],\n",
       " ['bahama', 3],\n",
       " ['eprakop', 1],\n",
       " ['nachling', 6],\n",
       " ['unbil', 2],\n",
       " ['reg', 684],\n",
       " ['knew', 9],\n",
       " ['august', 323],\n",
       " ['occas', 9],\n",
       " ['osbourn', 1],\n",
       " ['colioquak', 2],\n",
       " ['ow', 7485],\n",
       " ['transalta', 1],\n",
       " ['mdougla', 1],\n",
       " ['dine', 2],\n",
       " ['eldridg', 1],\n",
       " ['waymark', 5],\n",
       " ['petch', 1],\n",
       " ['orderli', 0],\n",
       " ['steward', 1],\n",
       " ['gtc', 69],\n",
       " ['marta', 55],\n",
       " ['vote', 19],\n",
       " ['bin', 156],\n",
       " ['fagen', 3],\n",
       " ['easi', 58],\n",
       " ['seafreight', 1],\n",
       " ['hetherington', 2],\n",
       " ['donni', 9],\n",
       " ['ngi', 115],\n",
       " ['montovano', 1],\n",
       " ['christensen', 3],\n",
       " ['norman', 3],\n",
       " ['voicemail', 13],\n",
       " ['babym', 1],\n",
       " ['meredith', 44],\n",
       " ['kponton', 10],\n",
       " ['xport', 3],\n",
       " ['winnetka', 1],\n",
       " ['dessert', 1],\n",
       " ['swroy', 2],\n",
       " ['roos', 20],\n",
       " ['txag', 2],\n",
       " ['orlando', 1],\n",
       " ['escobar', 1],\n",
       " ['lollar', 1],\n",
       " ['strict', 69],\n",
       " ['owner', 98],\n",
       " ['mokeen', 4],\n",
       " ['intermonth', 1],\n",
       " ['stadium', 1],\n",
       " ['comprehens', 5],\n",
       " ['agenda', 20],\n",
       " ['raheem', 3],\n",
       " ['educ', 160],\n",
       " ['sith', 2],\n",
       " ['!', 1178],\n",
       " ['fig', 29],\n",
       " ['sidrichga', 3],\n",
       " ['variabl', 4],\n",
       " ['denison', 2],\n",
       " ['paradis', 2],\n",
       " ['texaco', 57],\n",
       " ['coyot', 1],\n",
       " ['sched', 614],\n",
       " ['gut', 6],\n",
       " ['compusa', 1],\n",
       " ['cousin', 32],\n",
       " ['morrison', 1],\n",
       " ['berkeland', 1],\n",
       " ['mo', 4283],\n",
       " ['seriou', 1],\n",
       " ['peden', 1],\n",
       " ['carmin', 1],\n",
       " ['groupwis', 2],\n",
       " ['fluctuat', 2],\n",
       " ['sl', 350],\n",
       " ['reus', 2],\n",
       " ['genuiti', 0],\n",
       " ['jointli', 0],\n",
       " ['greatli', 0],\n",
       " ['complexion', 1],\n",
       " ['peacock', 1],\n",
       " ['radiat', 1],\n",
       " ['overpul', 1],\n",
       " ['ooop', 4],\n",
       " ['further', 166],\n",
       " ['coke', 2],\n",
       " ['wadey', 1],\n",
       " ['matiss', 1],\n",
       " ['documentari', 1],\n",
       " ['gilchrist', 1],\n",
       " ['pipelin', 380],\n",
       " ['transit', 70],\n",
       " ['anymor', 9],\n",
       " ['twice', 8],\n",
       " ['fade', 3],\n",
       " ['dupont', 14],\n",
       " ['bnp', 2],\n",
       " ['apt', 78],\n",
       " ['alter', 99],\n",
       " ['perlman', 5],\n",
       " ['augustmail', 1],\n",
       " ['shapiro', 2],\n",
       " ['licens', 10],\n",
       " ['command', 4],\n",
       " ['yeari', 0],\n",
       " ['bearden', 1],\n",
       " ['audienc', 8],\n",
       " ['tremend', 4],\n",
       " ['liedtk', 1],\n",
       " ['diskett', 1],\n",
       " ['blend', 2],\n",
       " ['keen', 8],\n",
       " ['april', 513],\n",
       " ['kedar', 1],\n",
       " ['andersen', 4],\n",
       " ['hoong', 1],\n",
       " ['rollin', 26],\n",
       " ['iii', 11],\n",
       " ['therein', 1],\n",
       " ['decad', 3],\n",
       " ['consecut', 1],\n",
       " ['ball', 84],\n",
       " ['firstworld', 2],\n",
       " ['alabama', 1],\n",
       " ['wa', 5433],\n",
       " ['mediaplay', 1],\n",
       " ['portacci', 1],\n",
       " ['broadli', 0],\n",
       " ['carrizo', 5],\n",
       " ['withstand', 5],\n",
       " ['pit', 121],\n",
       " ['psychmanag', 1],\n",
       " ['plc', 298],\n",
       " ['fire', 17],\n",
       " ['disneyworld', 1],\n",
       " ['perfer', 1],\n",
       " ['oquinn', 1],\n",
       " ['enorm', 4],\n",
       " ['palac', 2],\n",
       " ['jgilli', 1],\n",
       " ['brokeriq', 2],\n",
       " ['roberto', 2],\n",
       " ['webcast', 2],\n",
       " ['white', 76],\n",
       " ['interact', 5],\n",
       " ['mk', 34],\n",
       " ['overtim', 5],\n",
       " ['jana', 4],\n",
       " ['earthl', 20],\n",
       " ['martinez', 25],\n",
       " ['unless', 25],\n",
       " ['wt', 96],\n",
       " ['wellbor', 5],\n",
       " ['eta', 249],\n",
       " ['bad', 36],\n",
       " ['muniz', 1],\n",
       " ['merino', 1],\n",
       " ['wehr', 1],\n",
       " ['joa', 121],\n",
       " ['antoin', 18],\n",
       " ['reneau', 2],\n",
       " ['courtesi', 0],\n",
       " ['mcortino', 1],\n",
       " ['vac', 129],\n",
       " ['intermedi', 2],\n",
       " ['hoff', 23],\n",
       " ['blakey', 1],\n",
       " ['reasor', 1],\n",
       " ['gulteig', 1],\n",
       " ['parrish', 1],\n",
       " ['aransa', 2],\n",
       " ['marri', 7],\n",
       " ['aggrag', 5],\n",
       " ['bkrygodess', 1],\n",
       " ['assault', 1],\n",
       " ['tank', 6],\n",
       " ['mcomber', 1],\n",
       " ['loftu', 2],\n",
       " ['kutcha', 1],\n",
       " ['fritolay', 8],\n",
       " ['jdd', 1],\n",
       " ['leigh', 14],\n",
       " ['payton', 1],\n",
       " ['repurchas', 2],\n",
       " ['almond', 1],\n",
       " ['larson', 1],\n",
       " ['equip', 36],\n",
       " ['deep', 4],\n",
       " ['bmatul', 1],\n",
       " ['trivia', 2],\n",
       " ['marin', 10],\n",
       " ['jreveffo', 2],\n",
       " ['tung', 3],\n",
       " ['hard', 397],\n",
       " ['emeril', 1],\n",
       " ['steeli', 0],\n",
       " ['spangl', 1],\n",
       " ['flag', 40],\n",
       " ['princip', 10],\n",
       " ['mcmill', 57],\n",
       " ['bellflow', 1],\n",
       " ['cheek', 1],\n",
       " ['diversifi', 2],\n",
       " ['truro', 5],\n",
       " ['deboisblanc', 8],\n",
       " ['columbiaenergi', 0],\n",
       " ['loung', 1],\n",
       " ['whalen', 1],\n",
       " ['site', 200],\n",
       " ['drachenberg', 2],\n",
       " ['mpg', 3],\n",
       " ['bayley', 1],\n",
       " ['oregon', 2],\n",
       " ['pollacia', 1],\n",
       " ['gda', 3],\n",
       " ['egpfc', 22],\n",
       " ['dp', 99],\n",
       " ['stimpson', 1],\n",
       " ['son', 1362],\n",
       " ['excus', 5],\n",
       " ['desir', 22],\n",
       " ['drjuiceplu', 1],\n",
       " ['golden', 4],\n",
       " ['bayer', 10],\n",
       " ['feller', 3],\n",
       " ['merger', 27],\n",
       " ['jbaker', 1],\n",
       " ['outlin', 14],\n",
       " ['elektro', 1],\n",
       " ['world', 114],\n",
       " ['kinder', 21],\n",
       " ['sidelin', 5],\n",
       " ['richest', 1],\n",
       " ['joel', 4],\n",
       " ['colbert', 5],\n",
       " ['rufino', 1],\n",
       " ['mustard', 1],\n",
       " ['bridgett', 9],\n",
       " ['cate', 648],\n",
       " ['lind', 133],\n",
       " ['plane', 16],\n",
       " ['regard', 289],\n",
       " ['listbuild', 1],\n",
       " ['buhler', 5],\n",
       " ['mp', 2597],\n",
       " ['pull', 81],\n",
       " ['via', 151],\n",
       " ['besancon', 3],\n",
       " ['kreme', 1],\n",
       " ['pmac', 1],\n",
       " ['ring', 906],\n",
       " ['shot', 17],\n",
       " ['shave', 2],\n",
       " ['felip', 21],\n",
       " ['bangert', 2],\n",
       " ['clearli', 0],\n",
       " ['rule', 44],\n",
       " ['venu', 28],\n",
       " ['cernosek', 100],\n",
       " ['gasequip', 1],\n",
       " ['ie', 5143],\n",
       " ['amber', 29],\n",
       " ['pastor', 1],\n",
       " ['perrin', 1],\n",
       " ['lou', 169],\n",
       " ['video', 26],\n",
       " ['jeven', 1],\n",
       " ['cico', 5],\n",
       " ['earlier', 43],\n",
       " ['utilicorp', 2],\n",
       " ['cowart', 1],\n",
       " ['realign', 4],\n",
       " ['antioch', 2],\n",
       " ['nicola', 1],\n",
       " ['ac', 9892],\n",
       " ['earnshaw', 1],\n",
       " ['standpoint', 4],\n",
       " ['head', 469],\n",
       " ['tracker', 13],\n",
       " ['prayer', 46],\n",
       " ['cobo', 1],\n",
       " ['tom', 881],\n",
       " ['k', 21422],\n",
       " ['kick', 19],\n",
       " ['blackout', 5],\n",
       " ['garrick', 44],\n",
       " ['jloeskl', 1],\n",
       " ['thuraisingham', 1],\n",
       " ['burcham', 2],\n",
       " ['oblig', 24],\n",
       " ['sit', 1605],\n",
       " ['mailout', 1],\n",
       " ['myorder', 8],\n",
       " ['wil', 3734],\n",
       " ['relianc', 4],\n",
       " ['ragayl', 3],\n",
       " ['flower', 4],\n",
       " ['fit', 114],\n",
       " ['earth', 33],\n",
       " ['auditor', 2],\n",
       " ['pink', 5],\n",
       " ['geograph', 4],\n",
       " ['recap', 19],\n",
       " ['arimail', 1],\n",
       " ['anytim', 13],\n",
       " ['headlin', 5],\n",
       " ['benoit', 36],\n",
       " ['constrain', 7],\n",
       " ['conjunct', 3],\n",
       " ['lisewski', 0],\n",
       " ['tobacco', 6],\n",
       " ['concord', 1],\n",
       " ['jw', 10],\n",
       " ['hyvl', 11],\n",
       " ['ran', 2246],\n",
       " ['benita', 1],\n",
       " ['kreg', 3],\n",
       " ['ilen', 14],\n",
       " ['tmooney', 1],\n",
       " ['foyer', 2],\n",
       " ['jeter', 1],\n",
       " ['smi', 498],\n",
       " ['br', 2340],\n",
       " ['vice', 604],\n",
       " ['joan', 117],\n",
       " ['wallac', 5],\n",
       " ['eckermann', 1],\n",
       " ['zephaniah', 1],\n",
       " ['skutchin', 1],\n",
       " ['transm', 58],\n",
       " ['ledoux', 1],\n",
       " ['kuch', 1],\n",
       " ...]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#garder queles elments distinctes dans les deux listes\n",
    "hm = list(set(hm))\n",
    "sp = list(set(sp))\n",
    "\n",
    "#matrice contenant la frequence d'apparution de chaque mot \n",
    "hm_t=[[x,0] for x in hm]\n",
    "sp_t=[[x,0] for x in sp]\n",
    "\n",
    "sp = list(set(sp))\n",
    "for j in range(1000): #len(hm)\n",
    "    for i in range(len(data['class'])):  #len(data['class'])-5000\n",
    "        if data['class'][i]=='ham':\n",
    "            hm_t[j][1]+=data['text'][i].count(hm[j])\n",
    "            \n",
    "            \n",
    "for j in range(1000): #len(sp)\n",
    "    for i in range(len(data['class'])):  #len(data['class'])-5000\n",
    "        if data['class'][i]=='spam':\n",
    "            sp_t[j][1]+=data['text'][i].count(sp[j])\n",
    "            \n",
    "       \n",
    "\n",
    "    \n",
    "hm_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31605"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12395"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "counts = count_vectorizer.fit_transform(data['text'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtre BAISIEN MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtre BAISIEN MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'].values\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\"Subject: christmas tree farm pictures\\n\"]\n",
    "example_counts = count_vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer()),\n",
    "    ('classifier',  MultinomialNB()) ])\n",
    "\n",
    "pipeline.fit(data['text'].values, data['class'].values)\n",
    "p=pipeline.predict(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toutou/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails classified: 5172\n",
      "Score: 0.96115983853\n",
      "Confusion matrix:\n",
      "[[3628   44]\n",
      " [  72 1428]]\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n=len(data), n_folds=6)\n",
    "scores = []\n",
    "confusion = numpy.array([[0, 0], [0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = data.iloc[train_indices]['text'].values\n",
    "    train_y = data.iloc[train_indices]['class'].values\n",
    "\n",
    "    test_text = data.iloc[test_indices]['text'].values\n",
    "    test_y = data.iloc[test_indices]['class'].values\n",
    "\n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=SPAM)\n",
    "    scores.append(score)\n",
    "\n",
    "print('Total emails classified:', len(data))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtre BAISIEN BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fILTRE BAISIEN BernoulliNB\n",
    "\n",
    "classifierb = BernoulliNB()\n",
    "targets = data['class'].values\n",
    "classifierb.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifierb.predict(example_counts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelineb = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer()),\n",
    "    ('classifier',  BernoulliNB()) ])\n",
    "\n",
    "pipelineb.fit(data['text'].values, data['class'].values)\n",
    "pb=pipelineb.predict(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails classified: 5172\n",
      "Score: 0.959691336923\n",
      "Confusion matrix:\n",
      "[[3627   45]\n",
      " [  75 1425]]\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n=len(data), n_folds=4)\n",
    "scores = []\n",
    "confusion = numpy.array([[0, 0], [0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = data.iloc[train_indices]['text'].values\n",
    "    train_y = data.iloc[train_indices]['class'].values\n",
    "\n",
    "    test_text = data.iloc[test_indices]['text'].values\n",
    "    test_y = data.iloc[test_indices]['class'].values\n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=SPAM)\n",
    "    scores.append(score)\n",
    "\n",
    "print('Total emails classified:', len(data))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Filtre BAISIEN BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiersvm = SVC(kernel='linear', C=100)\n",
    "targets = data['class'].values\n",
    "classifiersvm.fit(counts, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifiersvm.predict(example_counts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelinesvm = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer()),\n",
    "    ('classifier',  SVC()) ])\n",
    "\n",
    "pipelinesvm.fit(data['text'].values, data['class'].values)\n",
    "psvm=pipelinesvm.predict(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total  des emails classifiés: 5172\n",
      "Score: 0.14916197263\n",
      "Matrice de Confusion :\n",
      "[[3662   10]\n",
      " [1378  122]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"total  des emails classifiés: 5172\\nScore: 0.151798421428\\nMatrice de Confusion :\\n[[3665    7]\\n [1376  124]] pour C=100 ce qui montre que notre scores'ameliore avec l'augmentation de C bien comme la théorie l'annonce \""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold = KFold(n=len(data), n_folds=6)\n",
    "scores = []\n",
    "confusion = numpy.array([[0, 0], [0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = data.iloc[train_indices]['text'].values\n",
    "    train_y = data.iloc[train_indices]['class'].values\n",
    "\n",
    "    test_text = data.iloc[test_indices]['text'].values\n",
    "    test_y = data.iloc[test_indices]['class'].values\n",
    "    pipelinesvm.fit(train_text, train_y)\n",
    "    predictions = pipelinesvm.predict(test_text)\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=SPAM)\n",
    "    scores.append(score)\n",
    "\n",
    "print('total  des emails classifiés:', len(data))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Matrice de Confusion :')\n",
    "print(confusion)\n",
    "\n",
    "\"\"\"Total des  emails classifiés: 5172\n",
    "Score: 0.145314516992\n",
    "matrice de Confusion :\n",
    "[[3665    7]\n",
    " [1381  119]] avec C =10 aussi pour C=1\"\"\"\n",
    "\n",
    "\"\"\"total  des emails classifiés: 5172\n",
    "Score: 0.14916197263\n",
    "Matrice de Confusion :\n",
    "[[3662   10]\n",
    " [1378  122]] pour C=100 ce qui montre que notre scores'ameliore avec l'augmentation de C bien comme la théorie l'annonce \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3665"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les mots qui apparaissent le plus sur :\n",
      "Cluster 0:\n",
      " subject\n",
      " deal\n",
      " gas\n",
      " com\n",
      " meter\n",
      " 00\n",
      " 000\n",
      " thanks\n",
      " http\n",
      " know\n",
      " 2000\n",
      " mmbtu\n",
      " nomination\n",
      " need\n",
      " 2001\n",
      " new\n",
      " daren\n",
      " let\n",
      " enron\n",
      " day\n",
      " 01\n",
      " attached\n",
      " 10\n",
      " hpl\n",
      " th\n",
      " time\n",
      " www\n",
      " price\n",
      " want\n",
      " message\n",
      "Cluster 1:\n",
      " ect\n",
      " enron\n",
      " hou\n",
      " hpl\n",
      " 2000\n",
      " xls\n",
      " 000\n",
      " subject\n",
      " nom\n",
      " file\n",
      " teco\n",
      " 2001\n",
      " attached\n",
      " tap\n",
      " hplno\n",
      " cc\n",
      " pm\n",
      " actuals\n",
      " hplo\n",
      " corp\n",
      " gas\n",
      " 10\n",
      " 01\n",
      " meter\n",
      " deal\n",
      " 03\n",
      " forwarded\n",
      " 02\n",
      " daren\n",
      " 30\n",
      "\n",
      "\n",
      "\n",
      "['subject', 'deal', 'gas', 'com', 'meter', '00', '000', 'thanks', 'http', 'know', '2000', 'mmbtu', 'nomination', 'need', '2001', 'new', 'daren', 'let', 'enron', 'day', '01', 'attached', '10', 'hpl', 'th', 'time', 'www', 'price', 'want', 'message']\n",
      "\n",
      "\n",
      "\n",
      "['ect', 'enron', 'hou', 'hpl', '2000', 'xls', '000', 'subject', 'nom', 'file', 'teco', '2001', 'attached', 'tap', 'hplno', 'cc', 'pm', 'actuals', 'hplo', 'corp', 'gas', '10', '01', 'meter', 'deal', '03', 'forwarded', '02', 'daren', '30']\n"
     ]
    }
   ],
   "source": [
    "targets = data['class'].values\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X = vectorizer.fit_transform(data['text'].values)\n",
    "\n",
    "true_k = 2\n",
    "classifiekm = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "classifiekm.fit(X,targets)\n",
    "cl0=[]\n",
    "cl1=[]\n",
    "print(\"les mots qui apparaissent le plus sur :\")\n",
    "Top_Mots = classifiekm.cluster_centers_.argsort()[:, ::-1]\n",
    "Termes = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in Top_Mots[i, :30]:\n",
    "        print(' %s' % Termes[ind])\n",
    "        if i==0:\n",
    "            cl0.append(Termes[ind])\n",
    "        else :\n",
    "            cl1.append(Termes[ind])\n",
    "        \n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(cl0)\n",
    "print(\"\\n\\n\")\n",
    "print(cl1)\n",
    "colors = ['b', 'g']\n",
    "markers = ['0', '', 's']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction d'un example:\n",
      "Cluster n°:\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction d'un example:\")\n",
    "\n",
    "Y = vectorizer.transform([\"Subject: christmas tree farm pictures\\n\"])\n",
    "predictions = classifiekm.predict(Y)\n",
    "print(\"Cluster n°:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelinekm = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer()),\n",
    "    ('classifier',  KMeans()) ])\n",
    "\n",
    "pipelinekm.fit(data['text'].values)\n",
    "pkm=pipelinekm.predict(examples)\n",
    "\n",
    "pkm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
